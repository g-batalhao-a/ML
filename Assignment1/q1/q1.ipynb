{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Linear Regression\n",
    "!pip install -U pandas\n",
    "!pip install -U numpy\n",
    "!pip install -U plotly==5.10.0\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.genfromtxt('../data/q1/linearX.csv', delimiter='\\n')\n",
    "y = np.genfromtxt('../data/q1/linearY.csv', delimiter='\\n')\n",
    "\n",
    "x = np.reshape(x,(-1,1))\n",
    "y = np.reshape(y,(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data\n",
    "fig = px.scatter(x[:,0],y[:,0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add intercept term to x\n",
    "x = np.append(np.ones((x.shape)),x,axis=1)\n",
    "\n",
    "print(x[:,1].mean(), x[:,1].std())\n",
    "# Normalize the data\n",
    "x[:,1] = (x[:,1] - x[:,1].mean()) / x[:,1].std()\n",
    "\n",
    "# Num of examples and features (with intercept)\n",
    "m = x.shape[0]\n",
    "n = x.shape[1]\n",
    "\n",
    "print(x[:,1].mean(), x[:,1].std())\n",
    "\n",
    "# Visualize data\n",
    "fig = px.scatter(x[:,1],y[:,0])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 1.a - Batch gradient descent method for optimizing J(θ)\n",
    "\n",
    "# Initialize params\n",
    "theta = np.zeros((2, 1))\n",
    "alpha = 1e-2\n",
    "\n",
    "# Prediction function: h(θ) = x^Tθ \n",
    "def predict(x, theta):\n",
    "    return x.dot(theta)\n",
    "\n",
    "# Cost function: J(θ) = 1/2m * Σ(y-h(θ))^2\n",
    "def cost(x,y,theta):\n",
    "    return (1/(2*m)) * np.sum((y - predict(x,theta))**2)\n",
    "\n",
    "cost_0 = cost(x, y, theta)\n",
    "print(\"Initial Cost value for the hypothesis with zero parameters={}\".format(cost_0))\n",
    "\n",
    "\n",
    "def cost_grd(x, y, theta):\n",
    "    return (1/m) * (np.zeros((2,1))+  x.T.dot(x.dot(theta)-y)) \n",
    "\n",
    "# Gradient descent function\n",
    "def batch_gradient_descent(x, y, theta, alpha, threshold=10e-8, num_iter=1000000):\n",
    "    \n",
    "    prev_cost=cost_0\n",
    "    c=0.0\n",
    "    cost_hist = np.array([cost_0])\n",
    "    theta_hist = theta\n",
    "    i=1\n",
    "    while True:\n",
    "        #Compute gradient and update theta\n",
    "        theta -= alpha * cost_grd(x,y,theta)\n",
    "        theta_hist = np.append(theta_hist, theta, axis=1)\n",
    "        c = cost(x,y,theta)\n",
    "        cost_hist = np.append(cost_hist,c)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "        if(i%1000==0):\n",
    "            print(\"Iteration: \",i,\" Cost: \",c)\n",
    "\n",
    "        # Stop if the cost is below a threshold or if the num of iterations is above a certain amount\n",
    "        if abs(cost_grd(x,y,theta)[1]) <= threshold or i >= num_iter:\n",
    "            print(abs(cost_grd(x,y,theta)[1]))\n",
    "            break\n",
    "        prev_cost = c\n",
    "        \n",
    "\n",
    "    return theta, cost_hist, theta_hist, i\n",
    "\n",
    "\n",
    "\n",
    "theta, cost_hist, theta_hist, iterations = batch_gradient_descent(x, y, theta, alpha)\n",
    "\n",
    "print(f'Cost of the model is {cost_hist[-1]} with {iterations} iterations')\n",
    "\n",
    "# Plot cost decrease\n",
    "fig = px.scatter(range(iterations), cost_hist)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.b - Plotting data and hypothesis function\n",
    "\n",
    "# Create predictions from our linear regression model\n",
    "predictions = x.dot(theta)\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "plt.scatter(x[:,1], predictions,label='Prediction')\n",
    "plt.scatter(x[:,1], y,label='Original values')\n",
    "plt.legend()\n",
    "plt.savefig('q1_b.png', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Question 1.c -  Drawing a 3d mesh of error function and the parameters\n",
    "import collections\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "def cost_plt(theta_0, theta_1, p):\n",
    "    return np.sum((p.y-p.x.dot(np.array([[theta_0],[theta_1]])))**2)\n",
    "\n",
    "# Create set of points with x and y\n",
    "P = collections.namedtuple('P', ['x', 'y'])\n",
    "points = P(x, y)\n",
    "\n",
    "# Create surface and contour to better see gradient descent working\n",
    "t0 = np.linspace(-0.5,3.0, 50)\n",
    "t1 = np.linspace(-0.5,3.0, 50)\n",
    "t0, t1 = np.meshgrid(t0, t1)\n",
    "c = np.array([cost_plt(t_0, t_1, points)for t_0, t_1 in zip(t0.ravel(), t1.ravel())])\n",
    "c_plt = c.reshape(t0.shape)\n",
    "\n",
    "# Create a mesh of points to plot in\n",
    "theta_0, theta_1 = np.meshgrid(theta_hist[0], theta_hist[1])\n",
    "c = np.array([cost_plt(theta0, theta1, points) for theta0, theta1 in zip(theta_0.ravel(), theta_1.ravel())])\n",
    "c_plt_grd = c.reshape(theta_0.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Graph\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(45, 20)\n",
    "ax.plot_surface(t0, t1, c_plt, alpha=0.3)\n",
    "\n",
    "ax.contour3D(t0, t1, c_plt)\n",
    "\n",
    "sc = ax.scatter([], [], [], marker='o', c='k')\n",
    "x_, y_, z_ = [], [], []\n",
    "\n",
    "def animate(i):\n",
    "    x_.append(theta_0.ravel()[i])\n",
    "    y_.append(theta_1.ravel()[i])\n",
    "    z_.append(c_plt_grd.ravel()[i])\n",
    "    sc._offsets3d = (x_, y_, z_)\n",
    "    return sc\n",
    "\n",
    "anim = FuncAnimation(fig, animate, frames=np.arange(0, 100), interval=200, repeat_delay=3000, blit=False)\n",
    "anim.save('q1_c.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1.d -  Drawing the contours of error function and the parameters\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "ax = fig.add_subplot(111)\n",
    "c=ax.contour(t0,t1,c_plt)\n",
    "\n",
    "p, = ax.plot([], [])\n",
    "x_, y_ = [], []\n",
    "\n",
    "def init():\n",
    "    p.set_data([], [])\n",
    "    return p,\n",
    "\n",
    "def animate_contour(i):\n",
    "    x_.append(theta_0.ravel()[i])\n",
    "    y_.append(theta_1.ravel()[i])\n",
    "    p.set_data(x_, y_)\n",
    "    return p,\n",
    "\n",
    "anim1 = FuncAnimation(fig, animate_contour, init_func=init, frames=np.arange(0, 100), interval=200, repeat_delay=3000, blit=False)\n",
    "anim1.save('q1_d.gif', writer='pillow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in [0.001, 0.025, 0.1]:\n",
    "    theta = np.zeros((2, 1))\n",
    "    theta, cost_hist, theta_hist, iterations = batch_gradient_descent(x, y, theta, step)\n",
    "    \n",
    "    # Create surface and contour to better see gradient descent working\n",
    "    t0 = np.linspace(-0.5,3.0, 50)\n",
    "    t1 = np.linspace(-0.5,3.0, 50)\n",
    "    t0, t1 = np.meshgrid(t0, t1)\n",
    "    c = np.array([cost_plt(t_0, t_1, points)for t_0, t_1 in zip(t0.ravel(), t1.ravel())])\n",
    "    c_plt = c.reshape(t0.shape)\n",
    "\n",
    "    # Create a mesh of points to plot in\n",
    "    theta_0, theta_1 = np.meshgrid(theta_hist[0], theta_hist[1])\n",
    "    c = np.array([cost_plt(theta0, theta1, points) for theta0, theta1 in zip(theta_0.ravel(), theta_1.ravel())])\n",
    "    c_plt_grd = c.reshape(theta_0.shape)\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    c=ax.contour(t0,t1,c_plt)\n",
    "\n",
    "    p, = ax.plot([], [])\n",
    "    x_, y_ = [], []\n",
    "\n",
    "    anim1 = FuncAnimation(fig, animate_contour, init_func=init, frames=np.arange(0, 100), interval=200, repeat_delay=3000, blit=False)\n",
    "    file = \"q1_e\"+str(step)+\".gif\" \n",
    "    anim1.save(file, writer='pillow')\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5d4af56a2e7987301107af7338a2f4c12a3584e52162a713fa580e431dd5f3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
